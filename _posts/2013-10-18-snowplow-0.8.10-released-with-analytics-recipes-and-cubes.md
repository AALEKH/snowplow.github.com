---
layout: blog-post
shortenedlink: Snowplow 0.8.10 released
title: Snowplow 0.8.10 released with analytics cubes and recipes 'baked in'
tags: snowplow analysis pivot bi
author: Yali
category: Releases
---

We are pleased to announce the release of Snowplow 0.8.10. In this release, we have taken many of the SQL recipes we have covered in the [Analysts Cookbook] [cookbook] and 'baked them' into Snowplow by providing them as views that can be added directly to your Snowplow data in Amazon Redshift or PostgreSQL.

1. [Background on this release] (#background)
2. [Reorganizing the Snowplow database] (#schema)
3. [Using the recipes: charting the number of uniques over time] (#recipe-use)
4. [Using the cubes: interrogating the visitors cube in Tableau] (#visitor-cube)
5. [Installing the views] (#setup)
6. [Next steps: where to go from here](#next-steps)

<a name="background"><h2>1. Background on this release</h2></a>

One of the things we've learnt from many new Snowplow users, is that they want to get up and running analyzing Snowplow data as fast as possible. Often, the first thing that new users want to do is plug in a familiar business intelligence tool, on top of Snowplow data, to start exploring and visualizing that data.

For those users, one of the frustrations with Snowplow, is that many analysis start with a SQL query on the Snowplow data, to transform it into a format suitable for analysing in a BI / OLAP tool. Whilst we believe it is a strength that Snowplow gives you the flexility to design and structure a wide range of different pivots / cubes using your Snowplow data, we recognise that for new users in particular, it would be nicer if they could dive straight into the data in our BI tool of choice.)

This release aims to bridge that gap. We've provided a range of recipes and cubes as views in SQL. All of these are suitable for being loaded into BI tools like Excel, ChartIO and Tableau, directly.

<!--more-->

<a name="schema"><h2>2. Reorganizing the Snowplow database</h2></a>

You'll notice with the new release that your Snowplow database has been reorganized:

1. The `events` table is now located in the `atomic` schema
2. There are three new schemas that contain "cubes" - views of the Snowplow data that can be consumed directly in a pivot / OLAP / BI tool e.g. PowerPivot or Tableau. These are `cubes_pages`, `cubes_visits` and `cubes_transactions`.
3. There are three new schemas that contain "recipes" - views of the Snowplow data that can be visualized directly in any graphics package. These are `recipes_basic`, `recipes_customer` and `recipes_catalog`  


<a name="recipe-use"><h2>3. Using an example recipe: plotting uniques by day in ChartIO</h2></a>

Let's start by showing how easy the views make it to start plotting Snowplow data in ChartIO. Log into ChartIO and create a new connection to your database, just as before, but this time update the `Schema name` field to be `recipes_basic` rather than `atomic`. (This is necessary, because ChartIO requires a different connection for each schema on your database, rather than a single connection per database.)

![chartio-setup] [chartio-connection]

Now go back into ChartIO and select to create a new graph. Select your new data source and then click the **Uniques And Visits By Day** from the list of views that appears below your new data source on the left hand side:

![chartio-setup-2] [chartio-select-view]

Now you can simply drag the relevant measures and dimensions over from the list into the design pane. Let's simply plot uniques by date: drag the **Date** dimension to the dimensions pane, and the **Uniques** measure over to the **Measures** pane:

![chartio-setup-select-dimensions] [chartio-setup-select-dimensions]

Now click **Save** to save the graph back to your dashboard. Simple visualization of Snowplow data with no SQL required!

![chartio-setup-3] [chartio-final-graph]

<a name="visitor-cube"><h2>4. Using an example cube: interrogating the visitors cube in Tableau</h2></a>

We've included a number of "cube views" in the new release. These can be opened directly into your pivoting tool of choice.

For this example, we're going to open the `cubes_visits.referer_entries_and_exits` view directly into Tableau.

Open up Tableau, select to create a new database connection, enter your database details. Select the `referer_entries_and_exits` view to connect to. 

![talbeau-setup-1][tableau-1]

Note: if you are connecting to the views in Redshift, you will need to add the new schemas to your `search_path` before they are visible in Tableau. You can, however, access them directly by selecting **Custom SQL** and entering `SELECT * FROM cubes_visits.referer_entries_and_exits`.

Tableau will ask whether you want to import all the data, or connect live. If you have a lot of data, we recommend connecting live.

![tableau-setup-2][tableau-2]

You can now drag and drop dimensions any of the dimensions and any of the metrics listed. For example, we can drag in `entry_page_path`, `visit_start_ts` and `visit_duration` to see how average visit lengths have changed per landing page over time:

![tableau-setup-3][tableau-3]

<a name="setup"><h2>5. Installing the views</h2></a>

If you're using Redshift, you will need to migrate your Snowplow events table from the `public` schema to the `atomic` schema. This can be done using [this migration script] [redshift-migration]. You will then you need to update your StorageLoader config file to ensure that from now on, all new data is loaded into the `atomic.events` table. You do this by updating the StorageLoader `config.yml` file so that the 

{% highlight yaml %}
:targets:
  - :name:     "Snowplow PostgreSQL"
    :type:     postgres 
    :host:     ec2-54-221-8-121.compute-1.amazonaws.com
    :database: snplow2
    :port:     5432
    :table:    atomic.events
{% endhighlight %}

Lastly you need to install the views. This should be straightforward: it is simply a case of running the SQL in the six files listed above into the database on Redshift or PostgreSQL where you house your Snowplow data. 

Specific instructions on how to perform this using the `psql` command line tool can be found [here][setup-views].


<a name="next-steps"><h2>6. Next steps: where to go from here</h2></a>

We'll be covering how to use the recipes and cubes in more detail in forthcoming blog posts and new recipes in the [Analysts Cookbook] [cookbook]. In the meantime, we recommend that curious users start experimenting with the different views, and refer to the underlying SQL to understand how they're created, and how they can tweak those statements to deliver the data formatted as they need.

[cookbook]: http://snowplowanalytics.com/analytics/index.html
[recipes-basic]: https://github.com/snowplow/snowplow/blob/feature/recipe-views/5-analytics/postgresql/recipes/recipes-basic.sql
[recipes-customer]: https://github.com/snowplow/snowplow/blob/feature/recipe-views/5-analytics/postgresql/recipes/recipes-customers.sql
[recipes-catalog]: https://github.com/snowplow/snowplow/blob/feature/recipe-views/5-analytics/postgresql/recipes/recipes-catalog.sql

[basic-recipes]: /analytics/basic-recipes.html
[customer-recipes]: http://snowplowanalytics.com/analytics/customer-analytics/overview.html
[catalog-recipes]: http://snowplowanalytics.com/analytics/catalog-analytics/overview.html
[catalog-analytics]: http://snowplowanalytics.com/analytics/catalog-analytics/overview.html

[cube-visits]: https://github.com/snowplow/snowplow/blob/feature/recipe-views/5-analytics/postgresql/cubes/cube-visits.sql
[cube-transactions]: https://github.com/snowplow/snowplow/blob/feature/recipe-views/5-analytics/postgresql/cubes/cube-transactions.sql
[cube-pages]: https://github.com/snowplow/snowplow/blob/feature/recipe-views/5-analytics/postgresql/cubes/cube-pages.sql

[setup-views]: https://github.com/snowplow/snowplow/wiki/Setting-up-the-prebuilt-views-in-Redshift-and-PostgreSQL
[chartio-connection]: /static/img/blog/2013/10/chartio-connection.png
[chartio-select-view]: /static/img/blog/2013/10/chartio-2.png
[chartio-setup-select-dimensions]: /static/img/blog/2013/10/chartio-select-dimensions.png
[chartio-final-graph]: /static/img/blog/2013/10/chartio-final-graph.png

[tableau-1]: /static/img/blog/2013/10/tableau-connection.JPG
[tableau-2]: /static/img/blog/2013/10/tableau-1.JPG
[tableau-3]: /static/img/blog/2013/10/tableau-visualization.JPG

[redshift-migration]: https://github.com/snowplow/snowplow/blob/master/4-storage/redshift-storage/sql/migrate_0.2.1_to_0.2.2.sql
[postgres-migration]: https://github.com/snowplow/snowplow/blob/master/4-storage/postgres-storage/sql/migrate_0.1.0_to_0.1.1.sql