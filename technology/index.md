---
layout: default
category: technology
title: Overview
weight: 1
---

# Under the hood

Snowplow consists of five loosely-coupled subsystems.

![architecture][architecture]

### 1. Trackers

* Trackers generate event data.
* Currently we have a [Javascript tracker] [js-tracker] for tracking user interactions on websites and web apps, and a [No-JS (also called 'pixel') tracker] [no-js-tracker] for tracking user behavior in web-environments that do not support Javascript e.g. emails. 
* We also offer a [Lua tracker][lua-tracker] for logging events directly from Lua applications e.g. games, and an [Arduino tracker][arduino-tracker] for sensor event analytics for the Internet of Things.
* Server side trackers (Java, Ruby and Python) and mobile trackers (iOS and Android) are on the [product roadmap] [roadmap].

The [Snowplow Tracker Protocol] [tracker-protocol] provides a standard way for *any* tracker to feed data into Snowplow. It is documented [here] [tracker-protocol].

### 2. Collectors

* Collectors receive Snowplow event data from trackers and log it to S3.
* Currently we have a [Cloudfront collector] [cf-collector] for tracking user activity across a single domain, and a [Clojure collector] [clj-collector] for tracking activity across multiple domains. The Clojure Collector runs on [Amazon Elastic Beanstalk] [beanstalk].

### 3. Enrichment

* The enrichment process takes the raw logs generated by the collector, cleans them up, checks them (validation) and enriches them. (E.g. infers geographical location from IP addresses, and referer data from referer URLs).
* The Enrichment process is written on top of [Scalding] [scalding], a Scala API library for [Cascading][cascading], a framework on Hadoop for building robust data pipelines. The Enrichment process runs on [Amazon EMR] [emr].

### 4. Storage

* Snowplow can be setup to load your event-level and customer-level data into one or more data stores, to enable analytics.
* Currently we support loading Snowplow data into [Amazon S3] [s3] (for processing by [Hive] [hive] / [Pig] [pig] / [Mahout] [mahout] on EMR) and [Amazon Redshift] [redshift] for analysis in more traditional tools (e.g. [R] [r], [Tableau] [tableau] and [Excel] [excel]). 
* We plan to add support for storing Snowplow data in [PostgreSQL] [postgres] in the near future, for Snowplow users who do not require Redshift's Terabyte-Petabyte scale solution.

Snowplow data is stored in each storage option above as close to the [Snowplow Canonical Event Model] [event-model] as possible. The data model is described [here] [event-model].

### 5. Analytics

Once your Snowplow data is available in storage, you can plug it into multiple different tools to crunch that data. Examples include:

* Create dashboards and scorecards with the data using [ChartIO] [chartio].
* Perform [OLAP analysis] [olap] (i.e. slice and dice different metrics against different metrics) using [PivotTables in Excel] [excel] or [Tableau] [tableau].
* Mine and model the data, to perform marketing, catalog or platform analytics, using [R] [r].
* Develop and run machine learning algorithms, using [Mahout] [mahout], [Python] [python] or [Weka] [weka] to develop recommendation engines or clusters audience by behaviour and interest.

## Learn more

* View the [Github repo] [github-repo] to see the source code for each subsystem listed above.
* View the [technical documentation] [tech-docs] to learn more about each subsystem.
* View the [setup guide] [setup-guide] for step-by-step instructions on installing individual subsystems, and Snowplow as a whole.

<img src="/static/img/APN_Standard_Technology_Partner.png" title="Amazon Web Services Technology Partner" width="250" />

*Snowplow Analytics is proud to be an Amazon Web Services Technology Partner.*


[js-tracker]: https://github.com/snowplow/snowplow/tree/master/1-trackers/javascript-tracker
[no-js-tracker]: https://github.com/snowplow/snowplow/tree/master/1-trackers/no-js-tracker
[cf-collector]: https://github.com/snowplow/snowplow/tree/master/2-collectors/cloudfront-collector
[clj-collector]: https://github.com/snowplow/snowplow/tree/master/2-collectors/clojure-collector

[scalding]: https://github.com/twitter/scalding
[cascading]: http://www.cascading.org/
[chartio]: https://github.com/snowplow/snowplow/wiki/Setting-up-ChartIO-to-visualize-Snowplow-data
[tableau]: https://github.com/snowplow/snowplow/wiki/Setting-up-Tableau-to-analyze-your-Snowplow-data
[excel]: https://github.com/snowplow/snowplow/wiki/Setting-up-Excel-to-analyze-Snowplow-data
[r]: https://github.com/snowplow/snowplow/wiki/Setting-up-R-to-perform-more-sophisticated-analysis-on-your-Snowplow-data
[weka]: http://weka.pentaho.com/
[mahout]: http://mahout.apache.org/
[python]: http://scikit-learn.org/stable/
[hive]: http://hive.apache.org/
[pig]: http://pig.apache.org/
[redshift]: http://aws.amazon.com/redshift/
[ice]: http://www.infobright.org/
[s3]: http://aws.amazon.com/s3/
[redshift]: http://aws.amazon.com/redshift/

[github-repo]: http://github.com/snowplow/snowplow
[snowplow-wiki]: http://github.com/snowplow/snowplow/wiki
[setup-guide]: https://github.com/snowplow/snowplow/wiki/Setting-up-Snowplow
[tech-docs]: https://github.com/snowplow/snowplow/wiki/Snowplow%20technical%20documentation
[architecture]: /static/img/technical-architecture.png
[lua-tracker]: https://github.com/snowplow/snowplow-lua-tracker
[arduino-tracker]: https://github.com/snowplow/snowplow-arduino-tracker
[olap]: /analytics/tools-and-techniques/converting-snowplow-data-into-a-format-suitable-for-olap.html
[roadmap]: https://github.com/snowplow/snowplow/wiki/Product-roadmap

[tracker-protocol]: https://github.com/snowplow/snowplow/wiki/snowplow-tracker-protocol
[event-model]: https://github.com/snowplow/snowplow/wiki/canonical-event-model
[beanstalk]: http://aws.amazon.com/elasticbeanstalk/
[emr]: http://aws.amazon.com/elasticmapreduce/
[postgres]: http://www.postgresql.org/