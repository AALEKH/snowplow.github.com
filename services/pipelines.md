---
layout: section
category: services
title: Custom datawarehouses and pipelines using EMR and Redshift
description: We help companies use Amazon EMR and Redshift to deliver custom datawarehouses and ETL pipelines that are robust and scalable
weight: 5
---

# Custom datawarehouses and pipelines using Amazon EMR and Redshift

Want to leverage Amazon Web Services and big data technologies to help you get get value out of your company-specific data?

Amazon Redshift is a fantastic data warehousing platform, that makes it possible and affordable to warehouse granular, event data to analyze in a wide range of BI and analytics tools. Amazon EMR is a perfect platform for building sophisticated, scalable ETL pipelines, especially when used with technologies like [Cascading] [cascading] and [Scalding] [scalding].

We have significant experience using both Redshift and EMR to build scalable, robust, fault tolerent data pipeline and data analytics infrastructure. We've been able to repurpose much of the Snowplow technology stack to implement client-specific solutions that load data in a custom (often JSON format) into a custom schema in Redshift for analysis.

## Fork Snowplow to handle your custom event dictionary

Want to log your own set of company-specific or application specific events, and analyse those events using Amazon Redshift? We've worked with clients to customise the Snowplow stack to accommodate their custom event dictionaries and analytics requirements.

## Load your raw JSON data into Redshift

JSON is a very popular format for storing event data. Analysing JSON data is not trivial: as a result, many companies are looking for ways to load their JSON data into Amazon Redshift, so that it can be analyzed faster, more easily, using a wider set of BI and analysis tools.

We have worked with a number of clients to modify the Snowplow technology stack to load custom JSONs into Redshift. For more information see [this blog post] [json-redshfit-blogpost].

## Load your bespoke log file formats into Redshift

Already logging your event data into a custom log file format, and interested in loading that data into Redshift? 

We have worked with a number of clients to modify the Snowplow technology stack to load custom log file formats into Redshift.

## Experts in developing and delivering data processing infrastructure on AWS

<img src="/static/img/APN_Standard_Technology_Partner.png" title="Amazon Web Services Technology Partner" width="250" />

*Snowplow Analytics is proud to be an Amazon Web Services Technology Partner.*

## Sounds interesting?

[Get in touch] [contact] to discuss your requirements with the Snowplow Professional Services team.

[contact]: /about/index.html
[hadoop]: http://hadoop.apache.org/
[cascading]: http://www.cascading.org/
[scalding]: https://github.com/twitter/scalding
[emr]: http://aws.amazon.com/elasticmapreduce/
[redshift]: http://aws.amazon.com/redshift/
[hive]: http://hive.apache.org/
[tableau]: http://www.tableausoftware.com/
[chartio]: https://chartio.com/
[r]: http://cran.r-project.org/
[json-redshfit-blogpost]: /blog/2013/11/20/loading-json-data-into-redshift/#weaknesses