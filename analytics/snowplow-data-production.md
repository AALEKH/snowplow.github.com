---
layout: page
group: analytics
sub_group: overview
title: How Snowplow produces data
shortened-link: Data production
weight: 2
---

# Understanding Snowplow data

The better you understand how your Snowplow data is produced, stored and structured, the easier it will be for you to query Snowplow data. There are three elements to understand about Snowplow data in particular:

1. [How Snowplow data is produced] [production]
2. [Where Snowplow data lives] [location]
3. [How Snowplow data is structured] [structure]

<a name="production"><h2>How Snowplow data is produced</h2></a>

*Note: this is just an overview geared towards data analysts. For a complete explanation of the Snowplow technology stack including source code, visit the [wiki] [wiki] and [Github repository] [github-repo]*.

![Snowplow architecture flowchart] [architecture]

Data is generated by [Snowplow trackers] [trackers]. In many cases, this will be the Snowplow [Javascript tracker] [js-tracker], that tracks user behavior across your website the same way that the Google Analytics or Omniture Javascript tracker works.

The Javascript tracker listens for events that happen on your website, be these _page views_, _add to baskets_, _video plays_, _transaction_ or any other event. When an event occurs, the tracker captures the relevant data that describes that event (e.g. the the transaction value and order ID, for a transaction event), and the relevant contextual information (e.g. the cookie ID, page data, browser data, operating system data, timestamp etc.) and sends that data to the Snowplow collector. In most cases, the tracker sends a single line of data for every single event that occurs. 

These packets of event data are received by [Snowplow collectors] [collectors]. Collectors have a single job to do: they receive the data from the tracker, add data (e.g. the timestamp that the data was received, the IP address that the data was received from) and push the event data packet to a queue where it is ready to be processed. There are currently three Snowplow collectors, but the one used most commonly is the [Cloudfront collector] [cloudfront-collector]: this uses Amazon's Cloudfront CDN to serve a tracking pixel. The tracker passes data to the Cloudfront collector by making a `GET` request for the tracking pixel, and appending the data points to pass into Snowplow to the query string for the `GET` request. The collector logs the request made, including the querystring, and stores the log to S3 for processing. (S3 is therefore used as a queue.)

An [enrichment process][enrich] then processes the raw logs, cleans them up, validates the data, enriches the data and then writes the tidied up data to one or more of the [storage] [storage] modules. The important thing to realise is that for every line of data in,  a line of data out is produced: the output data is as granular as the input data (i.e. at least one line for every event that occurs). The only difference is that the data has been formatted to make it easier to understand and query, and enriched with additional data points: for example, location is inferred from IP address, and referers are classified e.g. into search / social. 

Snowplow currently supports two enrichment processes: one that runs on Scalding / Cascading / EMR / Hadoop (and is batch based), and a second that runs on Amazon Kinesis (in near real-time). The Amazon Kinesis enrichment process is currently in beta.


## Understand how Snowplow data is generated?

[Learn more][location] about how Snowplow data is stored.

[production]: #production
[location]: snowplow-data-storage.html
[structure]: snowplow-table-structure.html
[github-repo]: http://github.com/snowplow/snowplow
[wiki]: http://github.com/snowplow/snowplow/wiki
[apachehive]: snowplow-data-storage.html#apachehive
[infobright]: snowplow-data-storage.html#infobright
[cloudfront]: http://aws.amazon.com/cloudfront/
[architecture]: /assets/img/architecture/conceptual-architecture.png
[trackers]: https://github.com/snowplow/snowplow/tree/master/1-trackers
[js-tracker]: https://github.com/snowplow/snowplow-javascript-tracker
[collectors]: https://github.com/snowplow/snowplow/tree/master/2-collectors
[cloudfront-collector]: https://github.com/snowplow/snowplow/tree/master/2-collectors/cloudfront-collector/
[enrich]: https://github.com/snowplow/snowplow/tree/master/3-enrich
[storage]: https://github.com/snowplow/snowplow/tree/master/4-storage
