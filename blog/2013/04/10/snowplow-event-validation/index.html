<!DOCTYPE html>
<html>
<head>
	
	<title>Towards high-fidelity web analytics - introducing Snowplow's innovative new event validation capabilities - SnowPlow Analytics</title>
	

	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link href="/static/css/styles.css" type="text/css" rel="stylesheet" />
	<link href="/static/css/pygments.css" type="text/css" rel="stylesheet" />
	

	<!--For the homepage slider-->
	<link rel="stylesheet" href="/static/css/nivo-slider.css" type="text/css" media="screen" />
	<link rel="stylesheet" href="/static/css/nivo-slider-theme-default.css" type="text/css" media="screen" />
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js"></script>
	<script src="/static/js/jquery-nivo-slider-pack.js" type="text/javascript" ></script>
</head>
<body>
	<!-- Google Tag Manager -->
	<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-DLRG"
	height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-DLRG');</script>
	<!-- End Google Tag Manager -->

	<div id="container">
		<div id="header" class="span-24">
  <div id="logo">
    <h1><a href="/">SnowPlow</a></h1>
    <p>Your web analytics data in your hands</p>
  </div>
  <div id="menu" class="span-15">
    <ul>
      <li ><a href="/product/index.html">Product</a></li>
      <li ><a href="/services/index.html">Services</a></li>
      <li ><a href="/analytics/index.html">Analytics</a></li>
      <li ><a href="/technology/index.html">Technology</a></li>
      <li  class="active" ><a href="/blog.html">Blog</a></li>
      <li ><a id="mail" href="/contact/index.html">Contact</a></li>
    </ul>
  </div>
</div>
	
		<div id="contents">
		<div class="post">
			10 Apr 2013
			<h1>Towards high-fidelity web analytics - introducing Snowplow's innovative new event validation capabilities</h1>
			<p>A key goal of the Snowplow project is enabling <strong>high-fidelity analytics</strong> for businesses running Snowplow.</p>

<p>What do we mean by high-fidelity analytics? Simply put, high-fidelity analytics means Snowplow faithfully recording <em>all</em> customer events in a rich, granular, non-lossy and unopinionated way.</p>

<p>This data is incredibly valuable: it enables companies to better understand their customers and develop and tailor products and services to them. Ensuring that the data is high fidelity is essential to ensuring that any operational and strategic decision making that&#8217;s made on the basis of that data is sound. Guaranteeing data fidelity is not a sexy topic. But it&#8217;s an important one.</p>

<p>Surprisingly, ensuring your data is high fidelity is <strong>not</strong> something that is enforced by other analytics products.</p>

<p><img alt='high-fidelity' src='/static/img/blog/2013/04/high-fidelity-2000.jpg' /></p>

<p>Why is Snowplow so unusual in aiming for high-fidelity analytics? Most often, analytics vendors sacrifice the goal of high-fidelity data at the altar of these three compromises:</p>

<ol>
<li><strong>Premature aggregation</strong> - when the data store gets too large, or the reports take too long to generate, it&#8217;s tempting to perform the aggregation and roll-up of the raw event data earlier, sometimes even at the point of collection. Of course this offers a huge potential performance boost to the tool, but at the cost of a huge degree of customer data fidelity</li>

<li><strong>Ignoring bad news</strong> - the nature of event data means that often incomplete, corrupted or plain wrong data is sent in to the analytics tool by the event trackers. Handling bad event data is complicated (let&#8217;s go shopping!). Instead of dealing with the complexity, most analytics packages just throw the bad data away silently; this is why tag audit companies like <a href='http://www.observepoint.com/'>ObservePoint</a> exist</li>

<li><strong>Being over-opinionated</strong> - customer analytics is full of challenging questions which need answering before you can analyse the data: do I track users by their first-party cookie, third-party cookie, business ID and/or IP address? Do I use the server clock, or the user&#8217;s clock to log the event time? When does a user session start and end? Because these questions can be difficult to answer, most analytics tools don&#8217;t ask them: instead they take an opinionated view of the &#8220;right answer&#8221; and silently enforce that view through their event collection, storage and analysis. By the time users realize that the logic enforced is one that does not work for their business, they are already tied to that vendor and the imperfect data set they have created with that vendor to date.</li>
</ol>

<p>To deliver on the goal of high-fidelity analytics, then, we&#8217;re trying to steer Snowplow around these three common pitfalls as best we can.</p>

<p>We have talked in detail on our website and wiki about avoiding pitfall #1, Premature aggregation. In short: we do <strong>no</strong> aggregation - Snowplow users have access to granular, event level data, so that they can work out how best they should aggregate it for each type of analysis they wish to perform.</p>

<p>We will blog more about our ideas to combat #3, Being over-opinionated, in the future.</p>

<p>For the rest of this blog post, though, we will look at our solution to pitfall #2, Ignoring bad news: namely, <strong>event validation</strong>.</p>
<!--more-->
<p>Our new Scalding-based event enrichment process (introduced in <a href='/blog/2013/04/03/snowplow-0.8.0-released-with-all-new-scalding-based-data-enrichment/'>our last blog post</a>) introduces the concept of <strong>event validation</strong>.</p>

<p>Instead of &#8220;ignoring bad news&#8221;, the Snowplow enrichment engine now validates that every logged event matches the format that we expect for Snowplow events - be they page views, ecommerce transactions, custom structured events or some other type of event. Events which do not match this format are stored in a new &#8220;Bad Rows&#8221; bucket in Amazon S3, along with the specific data validations which the event failed.</p>

<p>By way of example, here are a couple of <a href='https://github.com/snowplow/snowplow/wiki/snowplow-tracker-protocol#wiki-event'>custom structured events</a> generated by a ecommerce site running Snowplow; both of these events failed the new validation step in our Scalding ETL process. You will note that the bad rows are logged to the S3 bucket in JSON format - we have &#8220;pretty printed&#8221; the rows to make them easier to read:</p>
<div class='highlight'><pre><code class='json'><span class='p'>{</span>
  <span class='nt'>&quot;line&quot;</span><span class='p'>:</span> <span class='s2'>&quot;2012-11-14\t11:53:07\tDUB2\t3707\t92.237.59.86\tGET\td10wr4jwvp55f9.cloudfront.net\t\/ice.png\t200\thttps:\/\/www.psychicbazaar.com\/shop\/checkout\/?token=EC-6H7658847D893744L\tMozilla\/5.0%20(Windows%20NT%206.0)%20AppleWebKit\/537.11%20(KHTML,%20like%20Gecko)%20Chrome\/23.0.1271.64%20Safari\/537.11\tev_ca=ecomm&amp;ev_ac=checkout&amp;ev_la=id_city&amp;ev_pr=SUCCESS&amp;ev_va=Liverpool&amp;tid=404245&amp;uid=4434aa64ebbefad6&amp;vid=1&amp;lang=en-US&amp;refr=https%253A%252F%252Fwww.paypal.com%252Fuk%252Fcgi-bin%252Fwebscr%253Fcmd%253D_flow%2526SESSION%345DiuJgdNO9t8v06miTqv5EHhhGukkGNH3dfRqrKhe0i-UM9FCbVNg26G10sRC%2526dispatch%253D50a222a57771920b6a3d7b606239e4d529b525e0b7e69bf0224adecfb0124e9b61f737ba21b0819882a9058c69cd92dcdac469a145272506&amp;f_pdf=1&amp;f_qt=0&amp;f_realp=0&amp;f_wma=1&amp;f_dir=1&amp;f_fla=1&amp;f_java=1&amp;f_gears=0&amp;f_ag=1&amp;res=1920x1080&amp;cookie=1&amp;url=https%253A%252F%252Fwww.psychicbazaar.com%252Fshop%252Fcheckout%252F%253Ftoken%253DEC-6H7658847D893744L\t-\tHit\tAN6xpNsbS0JS05bqjmnbJdZDkl-cVkTPQsAJDlIOgAIG4hcPTTlMFA==&quot;</span><span class='p'>,</span>
  <span class='nt'>&quot;errors&quot;</span><span class='p'>:</span> <span class='p'>[</span>
    <span class='s2'>&quot;Field [ev_va]: cannot convert [Liverpool] to Float&quot;</span>
  <span class='p'>]</span>
<span class='p'>}</span>
<span class='p'>{</span>
  <span class='nt'>&quot;line&quot;</span><span class='p'>:</span> <span class='s2'>&quot;2012-11-14\t11:53:13\tDUB2\t3707\t92.237.59.86\tGET\td10wr4jwvp55f9.cloudfront.net\t\/ice.png\t200\thttps:\/\/www.psychicbazaar.com\/shop\/checkout\/?token=EC-6H7658847D893744L\tMozilla\/5.0%20(Windows%20NT%206.0)%20AppleWebKit\/537.11%20(KHTML,%20like%20Gecko)%20Chrome\/23.0.1271.64%20Safari\/537.11\tev_ca=ecomm&amp;ev_ac=checkout&amp;ev_la=id_state&amp;ev_pr=SUCCESS&amp;ev_va=Merseyside&amp;tid=462879&amp;uid=4434aa64ebbefad6&amp;vid=1&amp;lang=en-US&amp;refr=https%253A%252F%252Fwww.paypal.com%252Fuk%252Fcgi-bin%252Fwebscr%253Fcmd%253D_flow%2526SESSION%345DiuJgdNO9t8v06miTqv5EHhhGukkGNH3dfRqrKhe0i-UM9FCbVNg26G10sRC%2526dispatch%253D50a222a57771920b6a3d7b606239e4d529b525e0b7e69bf0224adecfb0124e9b61f737ba21b0819882a9058c69cd92dcdac469a145272506&amp;f_pdf=1&amp;f_qt=0&amp;f_realp=0&amp;f_wma=1&amp;f_dir=1&amp;f_fla=1&amp;f_java=1&amp;f_gears=0&amp;f_ag=1&amp;res=1920x1080&amp;cookie=1&amp;url=https%253A%252F%252Fwww.psychicbazaar.com%252Fshop%252Fcheckout%252F%253Ftoken%253DEC-6H7658847D893744L\t-\tHit\tXbvEfkx7BvngWyY23OLDvyFi8mXe2E_nhBaJwkzCG3aNxUng1jz4hQ==&quot;</span><span class='p'>,</span>
  <span class='nt'>&quot;errors&quot;</span><span class='p'>:</span> <span class='p'>[</span>
    <span class='s2'>&quot;Field [ev_va]: cannot convert [Merseyside] to Float&quot;</span>
  <span class='p'>]</span>
<span class='p'>}</span>
</code></pre></div>
<p>These validation errors occurred because the ecommerce site incorrectly tried to log customer address information in the <code>value</code> field of a custom structured event; the <code>value</code> field only supports numeric values (and is stored in Redshift in a float field). When we saw these validation errors, we notified the site and they corrected their Google Tag Manager implementation.</p>

<p>Currently these bad rows are simply stored for inspection in the Bad Rows bucket in S3, while Snowplow carries on with the raw event processing. This lets the Snowplow user tackle the tagging/data quality issues offline, without disrupting the loading of all their high-fidelity, now-validated event data into Redshift. It leaves open the possibility that the user can fix and reprocess the bad rows.</p>

<p>In the future we could look into ways of sending alerts when bad rows are generated, or even look into ways of automatically fixing bad rows and submitting them for re-processing.</p>

<p>This is straight forward stuff - but compare it with the approach taken by other web analytics vendors. If a Google Analytics user sends incorrectly configured data into GA, for example, one of two things happens:</p>

<ol>
<li>GA silently ignores the data</li>

<li>GA accommodates the data, so that it corrupts reports produced in GA</li>
</ol>

<p>For the GA user, spotting the error is impossible in either case. Not only has a data point been lost, but potentially an erroneous data point has been introduced, one that will be very hard to debug given that users can never inspect the underlying data.</p>

<p>This becomes more of a problem as we move to a Unviersal Analytics world: one in which companies feed GA with <strong>all</strong> their customer event data from a variety of systems. Ensuring that the system is fed with perfect data will only get harder, whilst dealing with situations where erroneous data has been pushed in will remain impossible.</p>

<p>That completes our brief look at event validation. We hope it is clear why this is such an important topic. For us at Snowplow, event validation is a key part of our quest for high-fidelity event analytics - so expect to hear more from us on this topic soon!</p>
			<div id="comments">
	<h2>Questions? Comments? Join the debate!</h2>
	 <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'snowplow'; // required: replace example with your forum shortname
            /* var disqus_identifier =  ; // unique ID so that disqus fetches the correct comments for each post
            var disqus_url =  ;
            var disqus_title =  ; */

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
		</div>
		<p>Return to the <a href="/blog.html">main blog page</a></p>

</div>

<div id="sidebar">
	<h1>Recent posts</h1>
	<ul>
		
			<li><a href="/blog/2013/04/18/measuring-content-page-performance-with-snowplow">Measuring content page performance with Snowplow (Catalog Analytics part 2)</a></li>
		
			<li><a href="/blog/2013/04/12/snowplow-0.8.1-released-with-referer-url-parsing">Snowplow 0.8.1 released with referer URL parsing</a></li>
		
			<li><a href="/blog/2013/04/12/online-catalog-analytics-with-snowplow">Online catalog analytics with Snowplow</a></li>
		
			<li><a href="/blog/2013/04/10/snowplow-event-validation">Towards high-fidelity web analytics - introducing Snowplow's innovative new event validation capabilities</a></li>
		
			<li><a href="/blog/2013/04/03/snowplow-0.8.0-released-with-all-new-scalding-based-data-enrichment">Snowplow 0.8.0 released with all-new Scalding-based data enrichment</a></li>
		
	</ul>

	
		<h1>Other</h1>
		<ul>
		
			
				<li><a href="/blog/2013/02/20/transferring-data-from-s3-to-redshift-at-the-command-line">Bulk loading data from Amazon S3 into Redshift at the command line</a></li>
			
				<li><a href="/blog/2013/02/18/ideas-coming-out-of-februarys-measurecamp">Reflections on Saturday's Measurecamp</a></li>
			
				<li><a href="/blog/2013/01/21/working-out-what-data-to-pass-into-your-tag-manager">What data should you be passing into your tag manager?</a></li>
			
				<li><a href="/blog/2013/01/20/snowplow-hits-202-stars">SnowPlow reaches 202 stars on GitHub</a></li>
			
				<li><a href="/blog/2013/01/18/using-snowplow-with-qubit-opentag">Implementing SnowPlow with QuBit's OpenTag</a></li>
			
		
		</ul>		
	
		<h1>Releases</h1>
		<ul>
		
			
				<li><a href="/blog/2013/04/12/snowplow-0.8.1-released-with-referer-url-parsing">Snowplow 0.8.1 released with referer URL parsing</a></li>
			
				<li><a href="/blog/2013/04/10/snowplow-event-validation">Towards high-fidelity web analytics - introducing Snowplow's innovative new event validation capabilities</a></li>
			
				<li><a href="/blog/2013/04/03/snowplow-0.8.0-released-with-all-new-scalding-based-data-enrichment">Snowplow 0.8.0 released with all-new Scalding-based data enrichment</a></li>
			
				<li><a href="/blog/2013/03/25/snowplow-tracker-for-arduino-released-sensor-and-event-analytics-for-the-internet-of-things">SnowPlow Arduino Tracker released - sensor and event analytics for the internet of things</a></li>
			
				<li><a href="/blog/2013/03/03/snowplow-0.7.6-released-with-redshift-data-warehouse-support">SnowPlow 0.7.6 released with Redshift data warehouse support</a></li>
			
		
		</ul>		
	
		<h1>Analytics</h1>
		<ul>
		
			
				<li><a href="/blog/2013/04/18/measuring-content-page-performance-with-snowplow">Measuring content page performance with Snowplow (Catalog Analytics part 2)</a></li>
			
				<li><a href="/blog/2013/04/12/online-catalog-analytics-with-snowplow">Online catalog analytics with Snowplow</a></li>
			
				<li><a href="/blog/2013/01/08/using-chartio-to-visualise-and-interrogate-snowplow-data">Using ChartIO to visualise and interrogate SnowPlow data</a></li>
			
				<li><a href="/blog/2012/12/17/transforming-snowplow-data-so-it-can-be-interrogated-by-olap-tools-like-tableau">Transforming SnowPlow data so that it can be interrogataed in BI / OLAP tools like Tableau, Qlikview and Pentaho</a></li>
			
				<li><a href="/blog/2012/10/24/web-analytics-with-tableau-and-snowplow">Performing web analytics on SnowPlow data using Tableau - a video demo</a></li>
			
		
		</ul>		
	
		<h1>Inside the Plow</h1>
		<ul>
		
			
				<li><a href="/blog/2013/03/20/rob-slifka-elasticity">Inside the Plow - Rob Slifka's Elasticity</a></li>
			
				<li><a href="/blog/2013/02/08/writing-hive-udfs-and-serdes">Writing Hive UDFs - a tutorial</a></li>
			
				<li><a href="/blog/2013/02/04/help-us-build-out-the-snowplow-event-model">Help us build out the SnowPlow Event Model</a></li>
			
				<li><a href="/blog/2013/01/09/from-etl-to-enrichment">The SnowPlow development roadmap for the ETL step - from ETL to enrichment</a></li>
			
				<li><a href="/blog/2013/01/07/the-clojure-collector-in-detail">Understanding the thinking behind the Clojure Collector, and mapping out its development going forwards</a></li>
			
		
		</ul>		
	
	

	<h1>Useful links</h1>
	<ul>
		<li><a href="/blog/atom.xml">Atom feed</a></li>
	</ul>
	<!--<strong>Tags</strong> -->
</div>

		<div id="footer">
	<p>Copyright © SnowPlow Analytics Limited 2012 - 2013.  All rights reserved</p>
</div>
	</div>
	<!-- Following Javascript function used by Disqus to count the number of comments for each blog post and display in the main index -->
	  <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'snowplow'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
        </script>
</body>
</html>