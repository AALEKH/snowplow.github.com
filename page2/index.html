<!DOCTYPE html>
<html>
<head>
	
	<title>The Snowplow blog - thoughts, musing and tutorials on event analytics from the Snowplow team - Snowplow Analytics</title>
	

	<link rel="icon" type="image/x-icon" href="/favicon.ico" />

	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link href="/static/css/styles.css" type="text/css" rel="stylesheet" />
	<link href="/static/css/pygments.css" type="text/css" rel="stylesheet" />
	
	<!--For the homepage slider-->
	<link rel="stylesheet" href="/static/css/nivo-slider.css" type="text/css" media="screen" />
	<link rel="stylesheet" href="/static/css/nivo-slider-theme-default.css" type="text/css" media="screen" />
	<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.0/jquery.min.js"></script>
	<script src="/static/js/jquery-nivo-slider-pack.js" type="text/javascript" ></script>
	<!--MathJax http://www.mathjax.org/-->
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_HTMLorMML.js"></script>
	<script type="text/javascript">
		MathJax.Hub.Config({
	      tex2jax: {
	        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
	      }
	    });
	    MathJax.Hub.Queue(function() {
	        var all = MathJax.Hub.getAllJax(), i;
	        for(i=0; i < all.length; i += 1) {
	            all[i].SourceElement().parentNode.className += ' has-jax';
	        }
    	});
	</script>
	<!-- end mathjax -->
	<!-- typekit -->
	<script type="text/javascript" src="//use.typekit.net/noo1diw.js"></script>
	<script type="text/javascript">try{Typekit.load();}catch(e){}</script>
	<!-- end typekit -->
</head>
<body>
	<!-- Google Tag Manager -->
	<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-DLRG"
	height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-DLRG');</script>
	<!-- End Google Tag Manager -->

	<div id="container">
		<div id="header" class="span-24">
  <div id="logo">
    <h1><a href="/"><img src="/static/img/snowplow-logo-website.png" title="Snowplow Analytics" /></a></h1>
  </div>
  <div id="menu" class="span-15">
    <ul>
      <li ><a href="/product/index.html">Product</a></li>
      <li ><a href="/services/index.html">Services</a></li>
      <li ><a href="/analytics/index.html">Analytics</a></li>
      <li ><a href="/technology/index.html">Technology</a></li>
      <li  class="active" ><a href="/blog.html">Blog</a></li>
      <li ><a id="mail" href="/about/index.html">About</a></li>
    </ul>
  </div>
</div>
	
		<div id="contents">
	
		<div class="post">
			07 Oct 2013
			<h1><a href="/blog/2013/10/07/announcing-our-winter-open-source-internship-program">Announcing our winter open source internship program</a></h1>
			 <span class="author">Author: <a href="/alex.html" rel="author">Alex Dean </a></span>
			<p>Applications for the new Snowplow Analytics open source internship program are now open! At Snowplow we are passionate about enterprise-strength open-source technology, and we are hugely excited to be offering paid internships for open source hackers this winter.</p>

<p>Snowplow Analytics is looking for one or two open source interns this winter (December through February), for 3-6 week paid internships. Our &#8220;winterns&#8221; will work directly on and contribute to data engineering projects within the <a href='https://github.com/snowplow'>Snowplow open source stack</a>. We have lots of ideas for cool projects to do around Snowplow - and if you have any suggestions of your own, we would love to hear them!</p>

<p><img alt='billion-dollar-brain' src='/static/img/blog/2013/10/billion-dollar-brain.png' /></p>
<p class='more'><a href='/blog/2013/10/07/announcing-our-winter-open-source-internship-program'>Read the rest of this entry</a></p>
		</div>
	
		<div class="post">
			01 Oct 2013
			<h1><a href="/blog/2013/10/01/snowplow-passes-500-stars">Snowplow passes 500 stars on GitHub</a></h1>
			 <span class="author">Author: <a href="/alex.html" rel="author">Alex Dean </a></span>
			<p>As of yesterday, the <a href='https://github.com/snowplow/snowplow'>Snowplow repository on GitHub</a> now has over 500 stars! We&#8217;re hugely excited to reach this milestone, having picked up <strong>300 new watchers</strong> since our <a href='/blog/2013/01/20/snowplow-hits-202-stars'>last milestone</a> in January.</p>

<p>Many thanks to everyone in the Snowplow community and on GitHub for their continuing support and interest!</p>

<p>Here&#8217;s a quick round-up of the most popular open source analytics projects on GitHub:</p>

<ul>
<li><a href='https://github.com/mnutt/hummingbird'>Hummingbird</a> (real-time web analytics) - 2,299 stars</li>

<li><a href='https://github.com/piwik/piwik'>Piwik</a> (web analytics) - 1,290 stars</li>

<li><a href='https://github.com/Countly/countly-server'>Countly</a> (mobile analytics) - 798 stars</li>

<li><a href='https://github.com/snowplow/snowplow'>Snowplow</a> - 501 stars</li>
</ul>

<p>So we&#8217;re in the challenger position but definitely nipping at the heels of the alternatives!</p>
<p class='more'><a href='/blog/2013/10/01/snowplow-passes-500-stars'>Read the rest of this entry</a></p>
		</div>
	
		<div class="post">
			30 Sep 2013
			<h1><a href="/blog/2013/09/30/book-review-instant-hive-essentials-how-to">Book review - Apache Hive Essentials How-to</a></h1>
			 <span class="author">Author: <a href="/yali.html" rel="author">Yali Sassoon </a></span>
			<p>Although it is no longer part of the core Snowplow stack, Apache Hive is the gateway drug that got us started on Hadoop. As some of our <a href='http://snowplowanalytics.com/blog/2013/09/03/using-qubole-to-analyze-snowplow-web-data/'>recent</a> <a href='http://snowplowanalytics.com/blog/2013/09/11/reprocessing-bad-data-using-hive-the-json-serde-and-qubole/'>blog posts</a> testify, Hive is still very much a part of our big data toolkit, and this will continue as we use it to roll out new features. (E.g. for analyzing custom unstructured events.) I suspect that many Hadoopers started out with Hive, before experimenting with the myriad other tools to crunch data using Hadoop.</p>

<p>We were therefore delighted to be invited to review <a href='http://www.packtpub.com/apache-hive-essentials-how-to/book?utm_source=blog&amp;utm_medium=link&amp;utm_campaign=bookmention'>Apache Hive Essentials How-to</a>, a new guide to Hive written by Darren Lee from <a href='http://www.bizo.com/home'>Bizo</a>.</p>
<a href='http://www.packtpub.com/apache-hive-essentials-how-to/book?utm_source=blog&amp;utm_medium=link&amp;utm_campaign=bookmention'>
	<img src='/static/img/blog/2013/09/instant-apache-hive-essentials.png' title='Hive how to guide' />
</a>
<p>For me, there are two totally different categories of technical book that I enjoy in completely different ways:</p>

<ol>
<li>Books that help me use tools more effectively: so I do more in less time.</li>

<li>Books that change the way I see the tools I use. These books step back from the practicalities of using the particular tools they cover to situate them in their proper context, and compare their usage with other tools. My favorite example in this cateogry is <a href='http://pragprog.com/book/btlang/seven-languages-in-seven-weeks'>Seven Languages in Seven Weeks</a>.</li>
</ol>

<p>Often, technical books fail because they try and accomplish <em>both</em> of the above.</p>

<p>Fortunately, that is <strong>not</strong> true of the <a href='http://www.packtpub.com/apache-hive-essentials-how-to/book?utm_source=blog&amp;utm_medium=link&amp;utm_campaign=bookmention'>Apache Hive Essentials How-to</a>. This is an uncompromisingly practical, focused book, that makes essential reading for anyone working with Hive.</p>
<p class='more'><a href='/blog/2013/09/30/book-review-instant-hive-essentials-how-to'>Read the rest of this entry</a></p>
		</div>
	
		<div class="post">
			27 Sep 2013
			<h1><a href="/blog/2013/09/27/how-much-does-snowplow-cost-to-run">How much does Snowplow cost to run, vs the competition?</a></h1>
			 <span class="author">Author: <a href="/yali.html" rel="author">Yali Sassoon </a></span>
			<p>We are very pleased to announce the release of the <a href='https://github.com/snowplow/snowplow-tco-model'>Snowplow Total Cost of Ownership Model</a>. This is a model we started developing <a href='http://snowplowanalytics.com/blog/2013/07/09/understanding-how-different-parts-of-the-Snowplow-data-pipeline-drive-AWS-costs/'>back in July</a>, to enable:</p>

<ul>
<li>Snowplow users and prospective users to better forecast their Snowplow costs on <a href='http://aws.amazon.com/'>Amazon Web Services</a> going forwards</li>

<li>The Snowplow Development Team to monitor how the cost of running Snowplow evolves as we build out the platform</li>
</ul>

<p>Modelling the costs associated with running Snowplow has not been straightforward: in the next few weeks, we&#8217;ll publish a series of blog posts exploring those challenges and how we tackled them. We&#8217;ll also review why we chose to build the model in <a href='http://cran.r-project.org/'>R</a> (rather than Excel), and explore some surprising aspects of what drives Snowplow costs on AWS, building on our <a href='http://snowplowanalytics.com/blog/2013/07/09/understanding-how-different-parts-of-the-Snowplow-data-pipeline-drive-AWS-costs/'>last blog post</a> on the subject.</p>

<p>In the meantime, <a href='https://github.com/snowplow/snowplow-tco-model'>download our TCO Model</a> and try it out yourself: it will let you model the cost of your particular Snowplow setup, and see how costs divide between the different AWS services.</p>

<p>In the rest of this blog post, we&#8217;ll focus on perhaps the most interesting output of the model: <strong>How expensive is it to run Snowplow vs our commercial competitors?</strong> Let&#8217;s start by comparing it with web analytics stalwarts Google Analytics and SiteCatalyst:</p>

<p><img alt='snowplow-premium-price-comparison' src='/static/img/price-comparison/snowplow-google-analytics-omniture-sitecatalyst-price-comparison.png' /></p>
<p class='more'><a href='/blog/2013/09/27/how-much-does-snowplow-cost-to-run'>Read the rest of this entry</a></p>
		</div>
	
		<div class="post">
			11 Sep 2013
			<h1><a href="/blog/2013/09/11/reprocessing-bad-data-using-hive-the-json-serde-and-qubole">Reprocessing bad rows of Snowplow data using Hive, the JSON Serde and Qubole</a></h1>
			 <span class="author">Author: <a href="/yali.html" rel="author">Yali Sassoon </a></span>
			<p>One of the distinguishing features of the Snowplow data pipeline is the handling of &#8220;bad&#8221; data. Every row of incoming, raw data is validated. When a row fails validation, it is logged in a &#8220;bad rows&#8221; bucket on S3 alongside the error message that was generated by the failed validation. That means you can keep track of the number of rows that fail validation, and have the opportunity to update and then reprocess those bad rows. (This makes Snowplow different from traditional web analytics platforms, that simply ignore bad rows of data, and provide no insight into the volume of incoming data that ends up being ignored.)</p>

<p>This functionality was crucial in spotting that, in mid-August, Amazon made an <a href='/blog/2013/09/05/snowplow-0.8.9-released-to-handle-cloudfront-log-file-format-change/'>undocumented update the CloudFront collector file format</a>. This resulted in a sudden spike in the number of &#8220;bad rows&#8221; generated by Snowplow, as the <code>cs-uri-query</code> field format changed from the format the Enrichment process expected. (For details of the change, see <a href='/blog/2013/09/05/snowplow-0.8.9-released-to-handle-cloudfront-log-file-format-change/'>this blog post</a>, and the links in it.) Amazon has since rolled back the update, and we have since updated Snowplow to be able to process rows in both formats. However, Snowplow users will have three weeks of data with lines of data missing, that ideally need to be reprocessed using the updated Snowplow version.</p>
<img src='/static/img/blog/2013/09/black_sheep.jpg' width='300' title='black sheet - can you spot bad data?' />
<p>In this blog post, we will walk through:</p>

<ol>
<li>How to use <a href='http://hive.apache.org/'>Apache Hive</a>, <a href='http://www.qubole.com/'>Qubole</a> and <a href='https://github.com/rcongiu'>Robert Congui&#8217;s</a> <a href='https://github.com/rcongiu/Hive-JSON-Serde'>JSON serde</a> to monitor the number of bad rows generated over time</li>

<li>How to use the same tools to reprocess the bad rows of data, so that they are added to your Snowplow data in Redshift / PostgreSQL</li>
</ol>

<p>The steps necessary to reprocess the data will be very similar to those required regardless of the reason that the reprocessing is necessary: as a result, this blog post should be useful for anyone interested in using the bad rows functionality to debug and improve the robustness of their event data collection. It should also be useful for anyone interested in using <a href='http://hive.apache.org/'>Hive</a> and the <a href='https://github.com/rcongiu/Hive-JSON-Serde'>JSON serde</a> to process JSON data in S3. (Bad row data is stored by Snowplow in JSON format.) We will use <a href='http://www.qubole.com/'>Qubole</a>, our preferred platform for running Hive jobs on data in S3, which we previously introduced in <a href='/blog/2013/09/03/using-qubole-to-analyze-snowplow-web-data/'>this blog post</a>.</p>

<ol>
<li><a href='/blog/2013/09/11/reprocessing-bad-data-using-hive-the-json-serde-and-qubole/#how-snowplow-handles-bad-rows'>Understanding how Snowplow handles bad rows</a></li>

<li><a href='/blog/2013/09/11/reprocessing-bad-data-using-hive-the-json-serde-and-qubole/#processing-bad-rows-data-using-json-serde-hive-qubole'>Processing the bad rows data using the JSON serde, Hive and Qubole</a></li>

<li><a href='/blog/2013/09/11/reprocessing-bad-data-using-hive-the-json-serde-and-qubole/#plot-bad-rows-over-time'>Plotting the number of bad rows over time</a></li>

<li><a href='/blog/2013/09/11/reprocessing-bad-data-using-hive-the-json-serde-and-qubole/#processing-bad-rows'>Reprocessing bad rows</a></li>
</ol>
<p class='more'><a href='/blog/2013/09/11/reprocessing-bad-data-using-hive-the-json-serde-and-qubole'>Read the rest of this entry</a></p>
		</div>
	

	<!-- Pagination links -->
	<div class="pagination">
		
			
			<a href="/blog.html">Previous</a>
			
		
		<span class="page_number">Page: 2 of 18</span>
		
			<a href="/page3" class="next">Next</a>
		
	</div>
</div>

<div id="sidebar">
	<h1>Recent posts</h1>
	<ul>
		
			<li><a href="/blog/2013/10/23/snowplow-team-in-budapest-to-speak-at-open-analytics-conference">Join the Snowplow team in Budapest the first week of November</a></li>
		
			<li><a href="/blog/2013/10/22/snowplow-0.8.11-released-supports-all-cloudfront-file-formats-and-other-improvements">Snowplow 0.8.11 released - supports all Cloudfront log file formats and host of small improvements for power users</a></li>
		
			<li><a href="/blog/2013/10/22/cohort-analysis-with-using-new-sql-recipes-and-chartio">Using the new SQL views to perform cohort analysis with ChartIO</a></li>
		
			<li><a href="/blog/2013/10/21/scripting-hadoop-part-1-adventures-with-scala-rhino-and-javascript">Scripting Hadoop, Part One - Adventures with Scala, Rhino and JavaScript</a></li>
		
			<li><a href="/blog/2013/10/18/snowplow-0.8.10-released-with-analytics-recipes-and-cubes">Snowplow 0.8.10 released with analytics cubes and recipes 'baked in'</a></li>
		
	</ul>

	
		<h1>Inside the Plow</h1>
		<ul>
		
			
				<li><a href="/blog/2013/09/27/how-much-does-snowplow-cost-to-run">How much does Snowplow cost to run, vs the competition?</a></li>
			
				<li><a href="/blog/2013/08/12/towards-universal-event-analytics-building-an-event-grammar">Towards universal event analytics - building an event grammar</a></li>
			
				<li><a href="/blog/2013/07/09/understanding-how-different-parts-of-the-Snowplow-data-pipeline-drive-AWS-costs">Unpicking the Snowplow data pipeline and how it drives AWS costs</a></li>
			
				<li><a href="/blog/2013/05/30/dealing-with-hadoops-small-files-problem">Dealing with Hadoop's small files problem</a></li>
			
				<li><a href="/blog/2013/04/10/snowplow-event-validation">Towards high-fidelity web analytics - introducing Snowplow's innovative new event validation capabilities</a></li>
			
		
		</ul>		
	
		<h1>Research</h1>
		<ul>
		
			
				<li><a href="/blog/2013/10/21/scripting-hadoop-part-1-adventures-with-scala-rhino-and-javascript">Scripting Hadoop, Part One - Adventures with Scala, Rhino and JavaScript</a></li>
			
		
		</ul>		
	
		<h1>Releases</h1>
		<ul>
		
			
				<li><a href="/blog/2013/10/22/snowplow-0.8.11-released-supports-all-cloudfront-file-formats-and-other-improvements">Snowplow 0.8.11 released - supports all Cloudfront log file formats and host of small improvements for power users</a></li>
			
				<li><a href="/blog/2013/10/18/snowplow-0.8.10-released-with-analytics-recipes-and-cubes">Snowplow 0.8.10 released with analytics cubes and recipes 'baked in'</a></li>
			
				<li><a href="/blog/2013/09/05/snowplow-0.8.9-released-to-handle-cloudfront-log-file-format-change">Snowplow 0.8.9 released to handle CloudFront log file format change</a></li>
			
				<li><a href="/blog/2013/08/05/snowplow-0.8.8-released-with-postgres-and-hive-support">Snowplow 0.8.8 released with Postgres and Hive support</a></li>
			
				<li><a href="/blog/2013/07/09/dotnet-support-added-to-referer-parser">.NET (C#) support added to referer-parser</a></li>
			
		
		</ul>		
	
		<h1>Recruitment</h1>
		<ul>
		
			
				<li><a href="/blog/2013/10/07/announcing-our-winter-open-source-internship-program">Announcing our winter open source internship program</a></li>
			
		
		</ul>		
	
		<h1>Other</h1>
		<ul>
		
			
				<li><a href="/blog/2013/10/23/snowplow-team-in-budapest-to-speak-at-open-analytics-conference">Join the Snowplow team in Budapest the first week of November</a></li>
			
				<li><a href="/blog/2013/10/01/snowplow-passes-500-stars">Snowplow passes 500 stars on GitHub</a></li>
			
				<li><a href="/blog/2013/09/30/book-review-instant-hive-essentials-how-to">Book review - Apache Hive Essentials How-to</a></li>
			
				<li><a href="/blog/2013/09/11/reprocessing-bad-data-using-hive-the-json-serde-and-qubole">Reprocessing bad rows of Snowplow data using Hive, the JSON Serde and Qubole</a></li>
			
				<li><a href="/blog/2013/07/19/snowplow-presentation-to-hadoop-user-group-london-aws-event">Snowplow presentation at the Hadoop User Group London AWS event</a></li>
			
		
		</ul>		
	
		<h1>Analytics</h1>
		<ul>
		
			
				<li><a href="/blog/2013/10/22/cohort-analysis-with-using-new-sql-recipes-and-chartio">Using the new SQL views to perform cohort analysis with ChartIO</a></li>
			
				<li><a href="/blog/2013/09/03/using-qubole-to-analyze-snowplow-web-data">Using Qubole to crunch your Snowplow web data using Apache Hive</a></li>
			
				<li><a href="/blog/2013/06/26/getting-started-with-r-for-data-analysis-and-visualization">Getting started using R for data analysis</a></li>
			
				<li><a href="/blog/2013/05/22/measuring-how-much-individual-items-in-your-catalog-contribute-to-inbound-marketing">Measuring how much traffic individual items in your catalog drive to your website</a></li>
			
				<li><a href="/blog/2013/05/20/performing-market-basket-analysis-with-r-arules-and-snowplow">Performing market basket analysis on web analytics data with R</a></li>
			
		
		</ul>		
	

	<h1>Useful links</h1>
	<ul>
		<li><a href="/blog/atom.xml">Atom feed</a></li>
	</ul>
	<!--<strong>Tags</strong> -->
</div>
		<div id="footer">
	<p>Copyright © Snowplow Analytics Limited 2012 - 2013.  All rights reserved</p>
</div>
	</div>
		<!-- Following Javascript function used by Disqus to count the number of comments for each blog post and display in the main index -->
	  	<script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'snowplow'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
        </script>
        <!-- begin olark code -->
		<script data-cfasync="false" type='text/javascript'>/*<![CDATA[*/window.olark||(function(c){var f=window,d=document,l=f.location.protocol=="https:"?"https:":"http:",z=c.name,r="load";var nt=function(){
		f[z]=function(){
		(a.s=a.s||[]).push(arguments)};var a=f[z]._={
		},q=c.methods.length;while(q--){(function(n){f[z][n]=function(){
		f[z]("call",n,arguments)}})(c.methods[q])}a.l=c.loader;a.i=nt;a.p={
		0:+new Date};a.P=function(u){
		a.p[u]=new Date-a.p[0]};function s(){
		a.P(r);f[z](r)}f.addEventListener?f.addEventListener(r,s,false):f.attachEvent("on"+r,s);var ld=function(){function p(hd){
		hd="head";return["<",hd,"></",hd,"><",i,' onl' + 'oad="var d=',g,";d.getElementsByTagName('head')[0].",j,"(d.",h,"('script')).",k,"='",l,"//",a.l,"'",'"',"></",i,">"].join("")}var i="body",m=d[i];if(!m){
		return setTimeout(ld,100)}a.P(1);var j="appendChild",h="createElement",k="src",n=d[h]("div"),v=n[j](d[h](z)),b=d[h]("iframe"),g="document",e="domain",o;n.style.display="none";m.insertBefore(n,m.firstChild).id=z;b.frameBorder="0";b.id=z+"-loader";if(/MSIE[ ]+6/.test(navigator.userAgent)){
		b.src="javascript:false"}b.allowTransparency="true";v[j](b);try{
		b.contentWindow[g].open()}catch(w){
		c[e]=d[e];o="javascript:var d="+g+".open();d.domain='"+d.domain+"';";b[k]=o+"void(0);"}try{
		var t=b.contentWindow[g];t.write(p());t.close()}catch(x){
		b[k]=o+'d.write("'+p().replace(/"/g,String.fromCharCode(92)+'"')+'");d.close();'}a.P(2)};ld()};nt()})({
		loader: "static.olark.com/jsclient/loader0.js",name:"olark",methods:["configure","extend","declare","identify"]});
		/* custom configuration goes here (www.olark.com/documentation) */
		olark.identify('9752-503-10-5227');/*]]>*/</script><noscript><a href="https://www.olark.com/site/9752-503-10-5227/contact" title="Contact us" target="_blank">Questions? Feedback?</a> powered by <a href="http://www.olark.com?welcome" title="Olark live chat software">Olark live chat software</a></noscript>
		<!-- end olark code -->
		<!-- Track Olark chats in GTM (so can pass data onto Snowplow) -->
		<script type="text/javascript">
		olark('api.chat.onMessageToOperator', function(event) {
		    dataLayer.push({'event': 'olarkMessageToOperator'});
		});
		olark('api.chat.onMessageToVisitor', function(event) {
		    dataLayer.push({'event': 'olarkMessageToVisitor'});
		});
		</script>
		<!-- end track olark code -->


</body>
</html>