<!DOCTYPE html>
<html>
<head>
	
	<title></title>
	

	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link href="/static/css/styles.css" type="text/css" rel="stylesheet" />
	<link href="/static/css/pygments.css" type="text/css" rel="stylesheet" />
	

	<!-- SnowPlow starts plowing -->
	<script type="text/javascript">
	var _snaq = _snaq || [];

	_snaq.push(['setAccount', 'd3v6ndkyapxc2w']);
	_snaq.push(['trackPageView']);
	_snaq.push(['enableLinkTracking']);

	(function() {
	var sp = document.createElement('script'); sp.type = 'text/javascript'; sp.async = true; sp.defer = true;
	sp.src = ('https:' == document.location.protocol ? 'https' : 'http') + '://d1fc8wv8zag5ca.cloudfront.net/sp.js';
	var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(sp, s);
	})();
	 </script>
	<!-- SnowPlow stops plowing -->	

	<!--Google Analytics tracking-->
	<script type="text/javascript">

	  var _gaq = _gaq || [];
	  _gaq.push(['_setAccount', 'UA-34290195-1']);
	  _gaq.push(['_trackPageview']);

	  (function() {
	    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	  })();

	</script>
	<!--Finish Google Analytics tracking-->
</head>
<body>
	<div id="container">
		<div id="header" class="span-24">
  <div id="logo">
    <h1><a href="/">SnowPlow</a></h1>
    <p>Your web analytics data in your hands</p>
  </div>
  <div id="menu" class="span-15">
    <ul>
      <li ><a href="/product/index.html">Product</a></li>
      <li ><a href="/services/index.html">Services</a></li>
      <li ><a href="/analytics/index.html">Analytics</a></li>
      <li ><a href="/technology/index.html">Technology</a></li>
      <li  class="active" ><a href="/blog.html">Blog</a></li>
      <li ><a id="mail" href="/contact/index.html">Contact</a></li>
    </ul>
  </div>
</div>
	
		<div id="contents">
	
		<a name="SnowPlow 0.4.10 released with Hive deserializer improvements" />
		<div class="post">
			11 Oct 2012
			<h1><a href="/blog/2012/10/11/snowplow-0.4.10-released">SnowPlow 0.4.10 released</a></h1>
			<p>We have just released version <strong>0.4.10</strong> of SnowPlow - people using 0.4.8 can jump straight to this version. This version updates:</p>

<ol>
<li>snowplow.js to version 0.7.0</li>

<li>the Hive deserializer to version 0.4.9</li>
</ol>

<p>Big thanks to community members <a href='https://github.com/mtibben'>Michael Tibben</a> from <a href='http://99designs.com'>99designs</a> and <a href='https://github.com/ramn'>Simon Andersson</a> from <a href='http://www.qwaya.com'>Qwaya</a> for their most-helpful contributions to this release!</p>

<h2 id='main_changes'>Main changes</h2>

<p>The main changes are as follows:</p>

<ul>
<li>The querystring parameter for site ID which the JavaScript tracker sends to your collector is renamed from <code>said</code> to <code>aid</code></li>

<li>The Hive-based ETL process now extracts the ecommerce tracking fields and the site ID field and adds them into your processed events table</li>

<li>We fixed a bug in the Hive deserializer where a partially-processed row was returned even if a fatal error was found in the row (now, a null row is returned instead)</li>
</ul>

<p>The rest of the changes were all enhancements to the Hive deserializer&#8217;s Specs2 test suite - these improvements should help to accelerate work on the deserializer (we have lots of cool new stuff we want to add to the deserializer!).</p>

<h2 id='new_event_table_fields'>New event table fields</h2>

<p>The new fields in the event table all relate directly to additional tracking functionality which was added to the JavaScript tracker in <a href='/blog/2012/09/06/snowplow-0.4.7-released/'>SnowPlow 0.4.7</a>. Specifically:</p>

<ol>
<li>The <code>setSiteId()</code> functionality is now extracted to the <code>app_id</code> field (short for application ID)</li>

<li>The ecommerce tracking functionality is now extracted to a set of <code>tr_</code> and <code>ti_</code> fields</li>
</ol>

<p>For details on the new fields, please review our latest <a href='/analytics/snowplow-table-structure.html'>Hive events table definition</a> - there is now a column indicating in which version a given field was added.</p>

<h2 id='how_to_get_the_new_version'>How to get the new version</h2>

<p>As usual, the new version of the Hive deserializer is available from the GitHub repository&#8217;s <a href='https://github.com/snowplow/snowplow/downloads'>Downloads</a> section as <strong>snowplow-log-deserializers-0.4.9.jar</strong>.</p>

<p>The updated snowplow.js is <a href='https://raw.github.com/snowplow/snowplow/master/1-trackers/javascript-tracker/js/snowplow.js'>available in our GitHub repository</a> for you to minify and upload, or alternatively you can use the one on our CDN:</p>

<pre><code>https://d1fc8wv8zag5ca.cloudfront.net/0.7.0/sp.js</code></pre>

<p>If you have any problems with either of these components, please <a href='https://github.com/snowplow/snowplow/issues'>raise an issue</a>!</p>

<h2 id='a_note_on_backwards_compatibility_for_the_events_table'>A note on backwards compatibility for the events table</h2>

<p>We will continue to add extra fields to the SnowPlow events table as we add extra capabilities to the ETL process - for example, we are working on functionality to extract geo-location information from IP addresses via MaxMind.</p>

<p>Starting with our new <code>app_id</code> field, we will be adding all such new fields to the <strong>end</strong> of our Hive events table definition. This will mean that you will <strong>not</strong> have to re-run the ETL process across all your historic raw logs, provided you do <strong>not</strong> need the data found in the new fields. This is because a Hive query across both the old event table format and the new table format works as long as you don&#8217;t explicitly query a new field.</p>

<p>In other words, Hive is futureproofed against new fields being added to the end of your underlying data files, and we&#8217;ll take advantage of this to improve backwards compatibility for our events table!</p>
			<span class="comments-link"><a href="/blog/2012/10/11/snowplow-0.4.10-released#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	
		<a name="Attlib launched" />
		<div class="post">
			11 Oct 2012
			<h1><a href="/blog/2012/10/11/attlib-0.0.1-released">Attlib - an open source library for extracting search marketing attribution data from referrer URLs</a></h1>
			<p>Last night we published <a href='https://github.com/snowplow/attlib'>Attlib</a>, an open source Ruby library for extracting search marketing attribution data from referrer URLs. In this post we talk through:</p>

<ol>
<li><a href='#what_attlib_does'>What Attlib does, and how to use it</a></li>

<li><a href='#install'>Installing Attlib</a></li>

<li><a href='#search_engine_yaml'>The search_engine.yml file</a></li>

<li><a href='#snowplow_stack'>Attlib as part of the SnowPlow stack</a></li>

<li><a href='#other_languages'>Attlib in other languages</a></li>

<li><a href='#snowplow_components_as_standalone_projects'>Making components of SnowPlow available as standalone open source projects</a></li>
</ol>
<a name='what_attlib_does' />
<h3 id='what_attlib_does_and_how_to_use_it'>What Attlib does, and how to use it</h3>

<p>Attlib is straightforward Ruby library for extracting seach marketing attribution data from referrer URLs. You give it a referrer URL: it then lets you now whether the URL is from a search engine. If it is, it will tell you which search engine it is, and what keywords were typed. (If those keywords are included in the query string - this is no longer the case for users logged in to Google, as documented <a href='http://googlewebmastercentral.blogspot.co.uk/2011/10/accessing-search-query-data-for-your.html'>here</a>.)</p>
<div class='highlight'><pre><code class='ruby'><span class='nb'>require</span> <span class='s1'>&#39;attlib&#39;</span>

<span class='n'>r</span> <span class='o'>=</span> <span class='no'>Referrer</span><span class='o'>.</span><span class='n'>new</span><span class='p'>(</span><span class='s1'>&#39;http://images.google.ca/imgres?q=hermetic+tarot&amp;hl=en&amp;biw=1189&amp;bih=521&amp;tbm=isch&amp;tbnid=BuQ_IyUbc25usM:&amp;imgrefurl=http://www.psychicbazaar.com/tarot-cards/15-the-hermetic-tarot.html&amp;imgurl=http://mdm.pbzstatic.com/tarot/the-hermetic-tarot/card-4.png&amp;w=1064&amp;h=1551&amp;ei=ue9AUMe7Osn9iwLZ-4H4Dw&amp;zoom=1&amp;iact=hc&amp;vpx=107&amp;vpy=48&amp;dur=2477&amp;hovh=271&amp;hovw=186&amp;tx=133&amp;ty=157&amp;sig=115588264602219115047&amp;page=4&amp;tbnh=162&amp;tbnw=120&amp;start=57&amp;ndsp=19&amp;ved=1t:429,r:12,s:57,i:291&#39;</span><span class='p'>)</span>

<span class='n'>r</span><span class='o'>.</span><span class='n'>is_search_engine?</span> <span class='c1'># True</span>
<span class='n'>r</span><span class='o'>.</span><span class='n'>search_engine</span> <span class='c1'># &#39;Google Images&#39;</span>
<span class='n'>r</span><span class='o'>.</span><span class='n'>keywords</span> 	<span class='c1'># &#39;hermetic tarot&#39;</span>
</code></pre>
</div><a name='install' />
<h3 id='installing_attlib'>Installing Attlib</h3>

<p>Attlib is available via a Ruby Gem. To install, simply run the following at the command line:</p>

<pre><code>sudo gem install attlib</code></pre>

<p>The sourcecode is available on <a href='https://github.com/snowplow/attlib'>Github</a></p>
<a name='search_engine_yaml' />
<h3 id='the_search_enginesyml_file'>The search_engines.yml file</h3>

<p>Extracting search engine names and keywords from a referrer URL is pretty straightforward. What is more complicated is keeping track of the myriad search engines that are out there, operating in different countries, the myriad domains they operate on, and the different query parameters that each of them uses to store the keywords.</p>

<p>Because the space is constantly evolving, none of this information (about search engines, parameters and domains) has been hard coded into Attlib. All of it is available in the <a href='https://github.com/snowplow/attlib/blob/master/data/search_engines.yml'>search_engines.yml</a> file, in the <a href='https://github.com/snowplow/attlib/tree/master/data'>data</a> in the repo.</p>

<p>The structure of the YAML file should be straightforward to understand. Each search engine is a top level item. For each search engine, two lists are given: one is a list of parameters used in that search engine&#8217;s query string to identify the keywords entered. The other is the list of domains on which that search engine operates. An extract is shown below:</p>
<div class='highlight'><pre><code class='yaml'><span class='l-Scalar-Plain'>Babylon</span><span class='p-Indicator'>:</span>
  <span class='l-Scalar-Plain'>parameters</span><span class='p-Indicator'>:</span> 
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>q</span>
  <span class='l-Scalar-Plain'>domains</span><span class='p-Indicator'>:</span> 
   <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>search.babylon.com</span>
   <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>searchassist.babylon.com</span>

<span class='l-Scalar-Plain'>Baidu</span><span class='p-Indicator'>:</span>
  <span class='l-Scalar-Plain'>parameters</span><span class='p-Indicator'>:</span> 
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>wd</span>
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>word</span>
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>kw</span>
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>k</span>
  <span class='l-Scalar-Plain'>domains</span><span class='p-Indicator'>:</span>
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>www.baidu.com</span>
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>www1.baidu.com</span>
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>zhidao.baidu.com</span>
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>tieba.baidu.com</span>
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>news.baidu.com</span>
    <span class='p-Indicator'>-</span> <span class='l-Scalar-Plain'>web.gougou.com</span>
</code></pre>
</div>
<p>Keeping this file up to date is a big job: one of our hopes releasing Attlib as an open source, standalone library, is that the community contributes to the file. We are enormously grateful to our friends at <a href='http://piwik.org/'>Piwik</a> as our initial version of the file is based on the Piwik equivalent <a href='https://github.com/piwik/piwik/blob/master/core/DataFiles/SearchEngines.php'>SearchEngines.php</a>, for the hard work they put into this version.</p>
<a name='snowplow_stack' />
<h3 id='attlib_as_part_of_the_snowplow_stack'>Attlib as part of the SnowPlow stack</h3>

<p>Our intention is to port <a href='https://github.com/snowplow/attlib'>Attlib</a> into Scala and integrate it into the SnowPlow stack: specifically the ETL phase. Both Ruby and Scala versions of Attlib will run based on the same <a href='https://github.com/snowplow/attlib/blob/master/data/search_engines.yml'>search_engines.yml</a> file.</p>
<a name='other_languages' />
<h3 id='attlib_in_other_languages'>Attlib in other languages</h3>

<p>As well as contributing to the search <a href='https://github.com/snowplow/attlib/blob/master/data/search_engines.yml'>search_engines.yml</a> file, we also hope that community members will develop versions of Attlib in other languages e.g. Python.</p>
<a name='snowplow_components_as_standalone_projects' />
<h3 id='making_components_of_snowplow_available_as_standalone_open_source_projects'>Making components of SnowPlow available as standalone open source projects</h3>

<p>Attlib is the first component in the SnowPlow stack that we have released as a standalone library. There are many more in the pipeline. (More on this in future blog posts :-) ). For us, this is a key part of the SnowPlow strategy:</p>

<ol>
<li>Keeping the SnowPlow architecture as loosely coupled as possible. We believe this makes SnowPlow robust, scalable and extendable</li>

<li>Grow the userbase of people using and contributing to each component. Processing web analytics data is a big job: there are many individual components involved, and each of them needs to evolve with the changing marketplace. Attlib is concerned today with extracting useful data from search engine referrers: but it is likely that as time goes on, we&#8217;ll want to extend it to capture data from other types of referrers e.g. social networks or affiliate sites. The bigger the community of people on top of those developments, the better for everyone in the web analytics community. Releasing each component as a standalone open source library should help grow that community.</li>
</ol>
<hr />
<p>Any questions about Attlib, or anything else in this post? Then <a href='/contact/index.html'>get in touch</a> with the SnowPlow team.</p>
			<span class="comments-link"><a href="/blog/2012/10/11/attlib-0.0.1-released#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	
		<a name="Why set your data free?" />
		<div class="post">
			24 Sep 2012
			<h1><a href="/blog/2012/09/24/what-does-snowplow-let-you-do">Why set your data free?</a></h1>
			<p>At Saturday&#8217;s <a href='http://ukdaa.co.uk/'>Measure Camp</a>, I had the chance to introduce SnowPlow to a large number of some incredibly thoughtful and insightful people in the web analytics industry.</p>

<p>With each person, I started by explaining that SnowPlow gave them direct access to their customer-level and event-level data. The response I got in nearly all cases was: <strong>what does having direct access to my web analytics data enable me to do, that I can&#8217;t do with Google Analytics / Omniture?</strong> It&#8217;s such a good question I thought I should publish an answer below:</p>

<h3 id='1_integrate_web_analytics_data_with_other_data_sources'>1. Integrate web analytics data with other data sources</h3>

<p>Integrating your web analytics data with other data sets enables you to answer a wide range of valuable business questions:</p>
<table><thead><tr><th><strong>Data source</strong></th><th><strong>Example business questions</strong></th></tr></thead><tbody><tr><td style='text-align: left;'>Marketing spend data e.g. AdWords, ad server data</td><td style='text-align: left;'>What is the return on my ad spend? How should I optimize my return on ad spend</td>
</tr><tr><td style='text-align: left;'>Customer data e.g. CRM, loyalty</td><td style='text-align: left;'>How does the online behaviour of my differnet customer segments vary by segment? Do online promotions drive offline sales? (Or vice versa?)</td>
</tr><tr><td style='text-align: left;'>Product / media catalogue data</td><td style='text-align: left;'>What are my most profitable product lines? Do different types of products attract different customer segments? What are the products that drive the most visits?</td>
</tr></tbody></table>
<p>SnowPlow makes integrating web analytics data with other data sources easier in a two ways:</p>

<ol>
<li>All your SnowPlow data is directly accessible in Apache Hive or Infobright. (So no expensive export process is required, prior to linking the data sets.)</li>

<li>Custom variables and event tracking give you plenty of opportunity to join e.g. customer IDs or campaigns names to enable <code>JOIN</code>s across data set</li>
</ol>

<p>For more details on how to perform <code>JOIN</code>s between SnowPlow data and other sources, see refer to the guide to <a href='/analytics/customer-analytics/joining-customer-data.html'>joining SnowPlow engagement data with other sources of customer data</a></p>

<h3 id='2_slice_and_dice_your_data_by_any_combination_of_dimensions__metrics_you_want'>2. Slice and dice your data by any combination of dimensions / metrics you want</h3>

<p>Google Analytics in particular only lets users create reports about of set combinations of dimensions and metrics. Examples of combinations that are <strong>not supported</strong> include:</p>

<ol>
<li>Number of unique visitors by product page</li>

<li>Different sources of traffic by product page (and how this changes over time)</li>

<li>Engagement levels (e.g. number of visits, number of page views, conversion rates) by traffic source</li>

<li>Improvements to conversion rates over time</li>
</ol>

<p>In contrast, because SnowPlow gives you access to the underlying data, it is possible to use BI tools like <a href='http://www.tableausoftware.com/'>Tableau</a> and <a href='http://www.microsoft.com/en-us/bi/powerpivot.aspx'>PowerPivot</a> to quickly slice and dice web analytics data by any dimensions / metrics you want. We&#8217;ll be posting examples of how to do this in the next few days.</p>

<h3 id='3_use_machine_learning_tools_on_your_web_analytics_data'>3. Use machine learning tools on your web analytics data</h3>

<p>Machine learning tools, and <a href='http://mahout.apache.org/'>Mahout</a> in particular, have created some new and exciting opportunities to:</p>

<ol>
<li>Develop product and content recommendation engines, based on user web behaviour. (E.g. users who viewed these content items, also viewed&#8230;)</li>

<li>Segment your audience by online behaviour</li>
</ol>

<p>SnowPlow makes it easy to extract the core input data you would need to feed a machine learning algorithm in a single query. (E.g. a matrix mapping users to products by page views / add to baskets / purchases etc.) We will be exploring ways to integrate SnowPlow with <a href='http://mahout.apache.org/'>Mahout</a> in a future blog post.</p>

<h3 id='4_view_data_for_individual_users_over_their_entire_lives'>4. View data for individual users over their entire lives</h3>

<p>Whereas reports on Google Analytics tend to be about visits, page views or transactions, SnowPlow lets you slice data by users over multiple visits, opening up a wide range of possibilities:</p>

<ol>
<li>Develop accurate models of customer lifetime value</li>

<li>Develop more rigorous approaches to attribution modelling, by capturing in granular detail which channels touched a user at different points in their lifecycle</li>
</ol>

<h3 id='5_interested_in_any__all_of_the_above'>5. Interested in any / all of the above?</h3>

<p>Then <a href='/product/get-started.html'>get started</a> with SnowPlow, or <a href='/contact/index.html'>get in touch</a> to find out more!</p>
			<span class="comments-link"><a href="/blog/2012/09/24/what-does-snowplow-let-you-do#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	
		<a name="SnowPlow 0.4.8 released with Hive deserializer improvements" />
		<div class="post">
			14 Sep 2012
			<h1><a href="/blog/2012/09/14/snowplow-0.4.8-released">SnowPlow 0.4.8 released</a></h1>
			<p>We have just released SnowPlow version <strong>0.4.8</strong>, with a set of enhancements to the existing Hive deserializer:</p>

<ol>
<li>The Hive deserializer now supports Amazon&#8217;s new CloudFront log file format (launched 12 September 2012) as well as the older format</li>

<li>The Hive deserializer now supports a tracking pixel called simply <code>i</code> (saving some characters versus <code>ice.png</code>) (<a href='https://github.com/snowplow/snowplow/issues/35'>issue #35</a>)</li>

<li>The Hive deserializer now works if the CloudFront distribution has Forward Query String = yes (<a href='https://github.com/snowplow/snowplow/pull/39'>issue #39</a>)</li>

<li>The Hive deserializer no longer dies if the calling page&#8217;s querystring is malformed</li>
</ol>

<p>Many thanks to community member <a href='https://github.com/mtibben'>Michael Tibben</a> from <a href='http://99designs.com'>99designs</a> in Melbourne for contributing the Forward Query String = yes fix!</p>

<h2 id='new_cloudfront_log_file_format'>New CloudFront log file format</h2>

<p>On 12th September 2012, Amazon <a href='http://aws.amazon.com/about-aws/whats-new/2012/09/04/cloudfront-support-for-cookies-and-price-classes/'>rolled out a new CloudFront log file format</a>, adding three additional fields onto the end of each line:</p>

<ul>
<li><strong>cs(Cookie)</strong>, the cookie header in the request (if any). Logging of this field is optional.</li>

<li><strong>x-edge-result-type</strong>, the result type of each HTTP(s) request (for example, cache hit/miss/error).</li>

<li><strong>x-edge-request-id</strong>, an encrypted string that uniquely identifies a request to help AWS troubleshoot/debug any issues.</li>
</ul>

<p>As always, please consult the Amazon CloudFront <a href='http://docs.amazonwebservices.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#LogFileFormat'>Developer Guide</a> for more information on these fields.</p>

<p>As part of this new <strong>0.4.8</strong> SnowPlow release, the Hive deserializer now supports the new CloudFront format as well as the old format: if you deploy the latest version of the deserializer, you should be able to process both old-format and new-format CloudFront logs without issue.</p>

<h2 id='support_for__as_the_tracking_pixel'>Support for <code>i</code> as the tracking pixel</h2>

<p>Currently the SnowPlow JavaScript tracker fires a GET request to a tracking pixel called <code>ice.png</code>. This works fine, but it makes more sense to call the pixel <code>i</code>, for two reasons:</p>

<ol>
<li>We free up 5 extra characters to use for sending data</li>

<li>A transparent GIF is smaller to send than a transparent PNG</li>
</ol>

<p>Thanks to <a href='https://github.com/shermozle/'>Simon Rumble</a> (author of <a href='https://github.com/shermozle/SnowCannon'>SnowCannon</a>) for pointing this out! In due course we will update the JavaScript tracker and CloudFront collector to implement this change (see issues <a href='https://github.com/snowplow/snowplow/issues/29'>#29</a> and <a href='https://github.com/snowplow/snowplow/issues/25'>#25</a>), but to start off we have added support for <code>i</code> to the new version of the Hive deserializer.</p>

<p>This is a small change, but highlights a wider point for SnowPlow development: in general, whenever we have a &#8220;breaking change&#8221; coming upstream, we will try to prepare for this change downstream first, to prevent any disruption to your use of SnowPlow.</p>

<h2 id='support_for_forward_query_string__yes'>Support for Forward Query String = yes</h2>

<p>Thanks to <a href='https://github.com/mtibben'>Michael Tibben</a> from <a href='http://99designs.com'>99designs</a> for spotting that the Hive deserializer does not work if your CloudFront distribution has Forward Query String set to Yes; Michael not only raised the issue but also provided a fix, many thanks Michael!</p>

<p>Most SnowPlow users will have Forward Query String in their CloudFront distribution set to No, so this issue will not arise for them; however this fix will be invaluable for anyone who does have it set to Yes. If you want to read more about this, please check out <a href='https://github.com/snowplow/snowplow/pull/39'>issue #39</a>.</p>

<p>We&#8217;re aware that our guide for setting up the CloudFront distribution is a bit out of date (which is how this issue can arise) - we will be refreshing the tracking pixel guide soon (<a href='https://github.com/snowplow/snowplow/issues/25'>issue #25</a>)! Many thanks for your patience.</p>

<h2 id='more_robust_querystring_handling'>More robust querystring handling</h2>

<p>A small change - we have made the code for extracting marketing attribution more robust. Specifically, the Hive deserializer no longer dies (i.e. throws a non-recoverable <code>SerDeException</code>) if the calling page&#8217;s URL has a malformed querystring.</p>

<p>An example of a malformed querystring would be something like:</p>

<pre><code>http://www.psychicbazaar.com/2-tarot-cards?n=48?utmsource=GoogleSearch&amp;...</code></pre>

<p>Note the two <code>?</code> questionmarks (the second one should be an <code>&amp;</code> ampersand). In the case of a malformed querystring like this, the five marketing attribution fields in the Hive output format for this row will all be set to null.</p>

<h2 id='deploying_the_new_version'>Deploying the new version</h2>

<p>The new version of the Hive deserializer is available from the GitHub repository&#8217;s <a href='https://github.com/snowplow/snowplow/downloads'>Downloads</a> section as <strong>snowplow-log-deserializers-0.4.8.jar</strong>. If you have any problems running it, please <a href='https://github.com/snowplow/snowplow/issues'>raise an issue</a>!</p>
			<span class="comments-link"><a href="/blog/2012/09/14/snowplow-0.4.8-released#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	
		<a name="SnowPlow 0.4.7 released with additional JavaScript tracking options" />
		<div class="post">
			06 Sep 2012
			<h1><a href="/blog/2012/09/06/snowplow-0.4.7-released">SnowPlow 0.4.7 released</a></h1>
			<p>We have just released SnowPlow version <strong>0.4.7</strong>. This release bumps the SnowPlow JavaScript tracker to version <strong>0.6</strong>, with two significant new features:</p>

<ol>
<li>The ability to set a site ID for your tracking - useful for multi-site publishers</li>

<li>The ability to log ecommerce transactions - useful for merchants wanting to track orders</li>
</ol>

<p>A huge thanks to community member <a href='https://github.com/ramn'>Simon Andersson</a> from <a href='http://www.qwaya.com'>Qwaya</a> for contributing the ecommerce tracking functionality - thank you Simon!</p>

<p>We&#8217;ll take a look at both of these new features in turn:</p>

<h2 id='site_id'>Site ID</h2>

<p>The SnowPlow JavaScript tracker now lets you set a site identifier before you start logging events. The new method for this is called <code>setSiteId()</code> - it takes one argument, the identifier you have assigned to this site. For example:</p>
<div class='highlight'><pre><code class='javascript'><span class='nx'>_snaq</span><span class='p'>.</span><span class='nx'>push</span><span class='p'>([</span><span class='s1'>&#39;setAccount&#39;</span><span class='p'>,</span> <span class='s1'>&#39;d3rkrsqld9gmqf&#39;</span><span class='p'>]);</span>
<span class='nx'>_snaq</span><span class='p'>.</span><span class='nx'>push</span><span class='p'>([</span><span class='s1'>&#39;setSiteId&#39;</span><span class='p'>,</span> <span class='s1'>&#39;CFe23a&#39;</span><span class='p'>]);</span>
<span class='nx'>_snaq</span><span class='p'>.</span><span class='nx'>push</span><span class='p'>([</span><span class='s1'>&#39;trackPageView&#39;</span><span class='p'>]);</span>
</code></pre>
</div>
<p>The querystring passed to your SnowPlow collector will now include the following parameter:</p>

<pre><code>...&amp;said=CFe23a&amp;...</code></pre>

<p>where <code>said</code> stands for <em>Site or App ID</em> - because we plan on using the same parameter for mobile and desktop app tracking as well.</p>

<p>This new feature should be helpful for anyone running multiple sites (or perhaps clients) against the same SnowPlow collector - it means that you can easily partition your SnowPlow events by site, whilst still being able to run cross-site analyses should you so wish.</p>

<p>Note that we haven&#8217;t yet added extracting <code>said</code> to our ETL process, but we have an <a href='https://github.com/snowplow/snowplow/issues/33'>open ticket for this</a>.</p>

<h2 id='ecommerce_transactions'>Ecommerce transactions</h2>

<p>To date, we have been analysing e-commerce transactions using SnowPlow by:</p>

<ul>
<li>Logging every <em>product add to basket</em> event</li>

<li>Logging every <em>product remove from basket</em> event</li>

<li>Netting these events off to determine the final contents of the order</li>
</ul>

<p>This approach works, but it adds complexity in the analysis step. Happily community member Simon Andersson has contributed an alternative solution: dedicated SnowPlow e-commerce transaction tracking, similar to the functionality found in the Google Analytics JavaScript API.</p>

<p>The idea is that you add the new tracking code to your shop&#8217;s checkout confirmation page, so that the completed order can be sent to SnowPlow. A complete example of the new tracking code looks like this:</p>
<div class='highlight'><pre><code class='javascript'><span class='kd'>var</span> <span class='nx'>orderId</span> <span class='o'>=</span> <span class='s1'>&#39;order-123&#39;</span><span class='p'>;</span>

<span class='c1'>// addTrans sets up the transaction, should be called first.</span>
<span class='nx'>_snaq</span><span class='p'>.</span><span class='nx'>push</span><span class='p'>([</span><span class='s1'>&#39;addTrans&#39;</span><span class='p'>,</span>
  <span class='nx'>orderId</span><span class='p'>,</span>                <span class='c1'>// order ID - required</span>
  <span class='s1'>&#39;&#39;</span><span class='p'>,</span>                     <span class='c1'>// affiliation or store name</span>
  <span class='s1'>&#39;8000&#39;</span><span class='p'>,</span>                 <span class='c1'>// total - required</span>
  <span class='s1'>&#39;&#39;</span><span class='p'>,</span>                     <span class='c1'>// tax</span>
  <span class='s1'>&#39;&#39;</span><span class='p'>,</span>                     <span class='c1'>// shipping</span>
  <span class='s1'>&#39;&#39;</span><span class='p'>,</span>                     <span class='c1'>// city</span>
  <span class='s1'>&#39;&#39;</span><span class='p'>,</span>                     <span class='c1'>// state or province</span>
  <span class='s1'>&#39;&#39;</span>                      <span class='c1'>// country</span>
  <span class='p'>]);</span>

<span class='c1'>// addItem is called for each item in the shopping cart.</span>
<span class='nx'>_snaq</span><span class='p'>.</span><span class='nx'>push</span><span class='p'>([</span><span class='s1'>&#39;addItem&#39;</span><span class='p'>,</span>
  <span class='nx'>orderId</span><span class='p'>,</span>                <span class='c1'>// order ID - required</span>
  <span class='s1'>&#39;1001&#39;</span><span class='p'>,</span>                 <span class='c1'>// SKU - required</span>
  <span class='s1'>&#39;Blue t-shirt&#39;</span><span class='p'>,</span>         <span class='c1'>// product name</span>
  <span class='s1'>&#39;&#39;</span><span class='p'>,</span>                     <span class='c1'>// category</span>
  <span class='s1'>&#39;2000&#39;</span><span class='p'>,</span>                 <span class='c1'>// unit price - required</span>
  <span class='s1'>&#39;2&#39;</span>                     <span class='c1'>// quantity - required</span>
  <span class='p'>]);</span>
<span class='nx'>_snaq</span><span class='p'>.</span><span class='nx'>push</span><span class='p'>([</span><span class='s1'>&#39;addItem&#39;</span><span class='p'>,</span>
  <span class='nx'>orderId</span><span class='p'>,</span>                <span class='c1'>// order ID - required</span>
  <span class='s1'>&#39;1002&#39;</span><span class='p'>,</span>                 <span class='c1'>// SKU - required</span>
  <span class='s1'>&#39;Red shoes&#39;</span><span class='p'>,</span>            <span class='c1'>// product name</span>
  <span class='s1'>&#39;&#39;</span><span class='p'>,</span>                     <span class='c1'>// category</span>
  <span class='s1'>&#39;4000&#39;</span><span class='p'>,</span>                 <span class='c1'>// unit price - required</span>
  <span class='s1'>&#39;1&#39;</span>                     <span class='c1'>// quantity - required</span>
  <span class='p'>]);</span>

<span class='c1'>// trackTrans sends the transaction to SnowPlow tracking servers.</span>
<span class='c1'>// Must be called last to commit the transaction.</span>
<span class='nx'>_snaq</span><span class='p'>.</span><span class='nx'>push</span><span class='p'>([</span><span class='s1'>&#39;trackTrans&#39;</span><span class='p'>]);</span>
</code></pre>
</div>
<p>The above example creates an order (aka &#8220;transaction&#8221;) with ID <code>order-123</code> and then adds two line items (two blue t-shirts and one pair of red shoes) as line items to the order. The final <code>trackTrans</code> call sends this complete order to SnowPlow as three separate events - one each for the order and its line items.</p>

<p>This new functionality should be useful for anybody who wants to track orders transacted in a online shopping cart such as Magento, PrestaShop or Spree.</p>

<p>Note that we haven&#8217;t yet added extracting these e-commerce orders to our ETL process, but we have an <a href='https://github.com/snowplow/snowplow/issues/34'>open ticket for this</a>.</p>

<h2 id='upgrading'>Upgrading</h2>

<p>We have made the minified JavaScript tracker version 0.6 available on this URL:</p>

<pre><code>http://d1fc8wv8zag5ca.cloudfront.net/0.6/sp.js</code></pre>

<p>There are no breaking changes with the previous version 0.5, so you can upgrade your existing SnowPlow JavaScript tracker without issue.</p>

<p>Note that we have now added versioning to the JavaScript tracker&#8217;s URL. This is because we have &#8220;breaking changes&#8221; to the JavaScript tracker in the pipeline (see e.g. issues <a href='https://github.com/snowplow/snowplow/issues/29'>#29</a> and <a href='https://github.com/snowplow/snowplow/issues/32'>#32</a>).</p>

<h2 id='thanks'>Thanks</h2>

<p>A final note to say thanks again to <a href='https://github.com/ramn'>Simon Andersson</a> for contributing the ecommerce tracking functionality! Community contributors like Simon A and Simon R(umble) are helping us to quickly make the SnowPlow vision a reality.</p>

<p>And of course, we welcome contributions across the five SnowPlow sub-systems. If you would like help implementing a new tracker, trying a different ETL approach or loading SnowPlow events into an alternative database, please <a href='mailto:contribute@snowplowanalytics.com'>get in touch</a>!</p>
			<span class="comments-link"><a href="/blog/2012/09/06/snowplow-0.4.7-released#disqus_thread" rel="nofollow">View Comments</a></span>
		</div>
	

	<!-- Pagination links -->
	<div class="pagination">
		
			<span class="previous">Previous</span>
		
		<span class="page_number">Page: 1 of 2</span>
		
			<a href="/page2" class="next">Next</a>
		
	</div>
</div>

<div id="sidebar">
	<h1>Recent posts</h1>
	<ul>
		
			<li><a href="/blog/2012/10/11/snowplow-0.4.10-released">SnowPlow 0.4.10 released</a></li>
		
			<li><a href="/blog/2012/10/11/attlib-0.0.1-released">Attlib - an open source library for extracting search marketing attribution data from referrer URLs</a></li>
		
			<li><a href="/blog/2012/09/24/what-does-snowplow-let-you-do">Why set your data free?</a></li>
		
			<li><a href="/blog/2012/09/14/snowplow-0.4.8-released">SnowPlow 0.4.8 released</a></li>
		
			<li><a href="/blog/2012/09/06/snowplow-0.4.7-released">SnowPlow 0.4.7 released</a></li>
		
			<li><a href="/blog/2012/08/21/amazon-glacier-launch">Amazon announces Glacier - lowers the cost of running SnowPlow</a></li>
		
			<li><a href="/blog/2012/08/20/snowplow-0.4.6-released">SnowPlow 0.4.6 released</a></li>
		
			<li><a href="/blog/2012/08/14/updated-hive-serde-released">Updated Hive SerDe released</a></li>
		
			<li><a href="/blog/2012/08/13/introducing-snow-cannon-a-node-js-collector-for-snowplow">SnowCannon - a node.js collector for SnowPlow</a></li>
		
			<li><a href="/blog/2012/08/02/snowplow-setup-documentation-overhauled">The setup guide has been overhauled</a></li>
		
	</ul>
	<h1>Useful links</h1>
	<ul>
		<li><a href="/blog/atom.xml">Atom feed</a></li>
	</ul>
	<!--<strong>Tags</strong> -->
</div>
		<div id="footer">
	<p>Copyright © SnowPlow Analytics Limited 2012.  All rights reserved</p>
</div>
	</div>
	<!-- Following Javascript function used by Disqus to count the number of comments for each blog post and display in the main index -->
	  <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'snowplow'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script'); s.async = true;
            s.type = 'text/javascript';
            s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
        </script>
</body>
</html>